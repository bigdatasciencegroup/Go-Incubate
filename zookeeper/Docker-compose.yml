version: '3'
services:

  # #Mongo database
  # mongo:
  #   image: mongo
  #   container_name: mongo
  #   networks:
  #     - dockerNet
  #   ports:
  #     - 27017:27017
  #   volumes:
  #     - mongo-data:/data/db #Volume location on `Host:Container` machine   

  #Zookeeper
  zookeeper:
    image: confluentinc/cp-zookeeper
    container_name: zookeeper   
    restart: always #Ensures that intermittent failures in the Docker environment do not result in unnecessary failures of the service.
    networks:
      - dockerNet
    ports:
      - 2181:2181 #Zookeeper
    environment:
      - ZOOKEEPER_SERVER_ID=1
      - ZOOKEEPER_CLIENT_PORT=2181
      - ZOOKEEPER_TICK_TIME=2000

  #Kafka
  kafka:
    image: confluentinc/cp-kafka
    container_name: kafka
    restart: always #Ensures that intermittent failures in the Docker environment do not result in unnecessary failures of the service.
    depends_on:
      - zookeeper
    networks:
      - dockerNet 
    ports:
      - 9092:9092 #Kafka broker - access port for external 
      # - 29092:29092 #Kafka broker - access port for internal
      # - 1099:1099 #JMX
    environment:
      - KAFKA_BROKER_ID=1
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
      # - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:29092, PLAINTEXT_HOST://localhost:9092   
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT_HOST://localhost:9092, PLAINTEXT://kafka:29092    
      # - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT_HOST://192.168.99.100:9092, PLAINTEXT://kafka:29092    
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT, PLAINTEXT_HOST:PLAINTEXT
      - KAFKA_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      # - KAFKA_JMX_PORT=1099
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
      # - KAFKA_REPLICA_FETCH_MAX_BYTES=1000000 #1GB
      # - KAFKA_MESSAGE_MAX_BYTES=1000000 #1GB. message.max.bytes <= replica.fetch.max.bytes

  #Producer to obtain data from RTSP and write into Kafka queue
  # goproducerrtsp:
  #   image: goproducerrtsp
  #   container_name: goproducerrtsp  
  #   restart: unless-stopped #Ensures that intermittent failures in the Docker environment do not result in unnecessary failures of the service.
  #   depends_on:
  #     - zookeeper
  #     - kafka 
  #   environment:
  #     - TOPICNAME=timeseries_1
  #     - KAFKAPORT=kafka:29092
  #     - RTSPLINK=rtsp://184.72.239.149/vod/mp4:BigBuckBunny_175k.mov
  #       # Image format = RGBA, uint8
  #       # Num of channels = 3
  #       # Total pixels = 38400
  #       # Image size = [160 240]
  #       # Num of rows = 160
  #       # Num of cols = 240
  #       # Format of Pix = [r(0,0),g(0,0),b(0,0),a(0,0), r(0,1),g(0,1),b(0,1),a(0,1), ... ]
  #   networks:
  #     - dockerNet 
  #       # To ensure that the containers in different docker-compose files communicate with each other, we place them on the same network. The complete network name is 'zookeeper_dockerNet'. It is derived by joining the name of the folder from which the network originates (i.e., zookeeper) and the name of the network (i.e., dockerNet).

  # kafdrop:
  #   image: thomsch98/kafdrop
  #   container_name: kafdrop
  #   depends_on:
  #     - zookeeper
  #     - kafka 
  #   networks:
  #     - dockerNet      
  #   ports:
  #     - 9010:9010
  #   environment:
  #     - ZK_HOSTS=zookeeper:2181
  #     - LISTEN=9010

  # prometheus:
  #   image: prom/prometheus:latest
  #   container_name: prometheus
  #   expose:
  #     - "9090"
  #   ports:
  #     - "9090:9090"
  #   depends_on:
  #     - kafka
  #     - zookeeper
  #   networks:
  #     - dockerNet

# volumes:
  # Volume location on host machine is not specified. 
  # Docker will create and manage these named volumes in a part of the host filesystem 
  # which is managed by Docker (i.e., /var/lib/docker/volumes/ on Linux).
  # mongo-data: 
networks:
  dockerNet:
    driver: bridge
